# 学习笔记：提示工程（PE）

> 目标：梳理与具体编程语言无关的通用概念、范式与方法论，给出可复用的模版与评测思路。

---

## 通用概念

- **角色与边界**：明确 System（规则/边界）、Developer（任务约束）、User（具体需求）三层输入的职责。
- **任务分解**：将复杂目标拆解为可验证的子目标；为每步定义输入/输出契约与完成判据。
- **结构化输出**：优先使用 JSON/YAML/表格等结构化格式，便于解析与自动化。
- **上下文管理**：给出最小充分的上下文（说明书、示例、反例、术语表），避免冗余噪音。
- **安全与合规**：避免泄露密钥/隐私；引导模型拒绝越权与猜测；对外输出做脱敏与校验。

---

## 常用范式

- **指令式（Instruction）**：清晰描述目标、约束、输出格式与评分标准。
- **少样本（Few-shot）**：提供若干高质量示例与反例，教会模型风格与边界。
- **思维链（CoT）/拆解（ToT）**：鼓励逐步推理；对外仅保留结论，隐藏中间推理可减少越权风险。
- **自一致性（Self-Consistency）**：多次采样取众数或聚合；在需要稳定性的场景降低温度。
- **检索增强（RAG）**：用外部知识库补齐事实，避免幻觉；保留来源引用。
- **工具调度（Tool-Use）**：把计算/搜索/API 调用外包给工具，模型负责决策与编排。

---

## 提示模版（可直接复用）

- **任务约束模版**：
```text
你是{角色}，请完成{任务目标}。
必须遵守：
- 输出语言：{zh|en}
- 风格：{简洁|正式|开发者友好}
- 约束：{长度<=N，禁止…，必须…}
- 结构化输出：以JSON返回：{schema}
验收标准：{判据1, 判据2}
```

- **Few-shot 模版（含反例）**：
```text
【术语表】{term: definition, ...}
【示例】
- 输入：...
  输出：{...}
- 输入：...
  输出：{...}
【反例】
- 输入：...
  错误原因：...
  期望修正：{...}
```

- **结构化评测 Rubric（面向自动化）**：
```json
{
  "criteria": [
    {"name":"完整性","weight":0.4},
    {"name":"准确性","weight":0.4},
    {"name":"格式符合","weight":0.2}
  ],
  "pass": {"score_min":0.8}
}
```

---

## 评测与保障（Evals & Guardrails）

- **自动化评测**：基准集（prompt->golden），覆盖常见与极端输入；离线/在线 A/B；漂移监测。
- **事实性/一致性**：使用 RAG 来源对齐检查；用规则或二级模型做 JSON Schema 校验。
- **可观测性**：记录 prompt/响应/工具调用/延时/代价；对错误样例进行归因与回放。
- **红队测试**：越权、注入、特设攻击；输出脱敏与正则拦截。

---

## 与本项目的关联（Paradox Language Support）

- **本地化文本**：提供统一提示模版进行翻译与润色，确保术语一致与格式合规。
- **规则解释/摘要**：对 CWT config/脚本片段生成摘要或注释；引导严格引用来源。
- **意图到操作**：将“用户意图”映射为 IDE 操作建议（跳转、修复、模板），输出结构化 JSON。
- **错误说明**：对检查结果生成简明解释与修复步骤，避免幻觉性建议。

---

## 可扩展内容

- **多角色协作**：Reviewer/Planner/Executor 分工与对话回合控制。
- **安全与注入防护**：系统提示合并策略、边界符、反注入测试清单。
- **成本与延迟优化**：缓存、提示压缩、语义检索、流式与背压。
- **跨语言一致性**：在多语种/多地区版本下的风格与术语统一策略。

---

## 参考链接

- **OpenAI Prompt Engineering 指南**：https://platform.openai.com/docs/guides/prompt-engineering
- **Anthropic Prompt Library**：https://docs.anthropic.com/claude/prompt-library
- **原则与模式汇编（Awesome Prompts）**：https://github.com/f/awesome-chatgpt-prompts
